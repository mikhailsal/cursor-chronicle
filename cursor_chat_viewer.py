#!/usr/bin/env python3
"""
Cursor Chat Viewer
–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –¥–∏–∞–ª–æ–≥–∏ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö Cursor IDE —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π 
–ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤.
"""

import sqlite3
import json
import os
import argparse
import signal
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional
import urllib.parse
import base64

# Handle broken pipe gracefully
signal.signal(signal.SIGPIPE, signal.SIG_DFL)


class CursorChatViewer:
    def __init__(self):
        self.cursor_config_path = Path.home() / ".config" / "Cursor" / "User"
        self.workspace_storage_path = (
            self.cursor_config_path / "workspaceStorage"
        )
        self.global_storage_path = (
            self.cursor_config_path / "globalStorage" / "state.vscdb"
        )
        
        # Tool type mapping
        self.tool_types = {
            1: "üîç Codebase Search",
            3: "üîé Grep Search", 
            5: "üìñ Read File",
            6: "üìÅ List Directory",
            7: "‚úèÔ∏è Edit File",
            8: "üîç File Search",
            9: "üîç Codebase Search",
            11: "üóëÔ∏è Delete File",
            12: "üîÑ Reapply",
            15: "‚ö° Terminal Command",
            16: "üìã Fetch Rules",
            18: "üåê Web Search",
            19: "üîß MCP Tool"
        }
    
    def get_projects(self) -> List[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤ —Å –∏—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏"""
        projects = []
        
        for workspace_dir in self.workspace_storage_path.iterdir():
            if not workspace_dir.is_dir():
                continue
                
            workspace_json = workspace_dir / "workspace.json"
            state_db = workspace_dir / "state.vscdb"
            
            if not workspace_json.exists() or not state_db.exists():
                continue
            
            try:
                # –ß–∏—Ç–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–µ–∫—Ç–µ
                with open(workspace_json, 'r') as f:
                    workspace_data = json.load(f)
                
                folder_uri = workspace_data.get('folder', '')
                if folder_uri.startswith('file://'):
                    folder_path = urllib.parse.unquote(folder_uri[7:])
                    project_name = os.path.basename(folder_path)
                else:
                    project_name = folder_uri
                
                # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∫–æ–º–ø–æ–∑–µ—Ä–æ–≤ –∏–∑ –±–∞–∑—ã
                conn = sqlite3.connect(state_db)
                cursor = conn.cursor()
                
                cursor.execute(
                    "SELECT value FROM ItemTable WHERE key = "
                    "'composer.composerData'"
                )
                result = cursor.fetchone()
                
                if result:
                    composer_data = json.loads(result[0])
                    composers = composer_data.get('allComposers', [])
                    
                    # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—ã–π —Å–≤–µ–∂–∏–π –¥–∏–∞–ª–æ–≥
                    latest_dialog = None
                    if composers:
                        latest_dialog = max(
                            composers, key=lambda x: x.get('lastUpdatedAt', 0)
                        )
                    
                    projects.append({
                        'workspace_id': workspace_dir.name,
                        'project_name': project_name,
                        'folder_path': (
                            folder_path if folder_uri.startswith('file://')
                            else folder_uri
                        ),
                        'composers': composers,
                        'latest_dialog': latest_dialog,
                        'state_db_path': str(state_db)
                    })
                
                conn.close()
                
            except Exception:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø—Ä–æ–µ–∫—Ç–∞ {workspace_dir.name}")
                continue
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø—Ä–æ–µ–∫—Ç—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞
        projects.sort(
            key=lambda x: x['latest_dialog'].get('lastUpdatedAt', 0)
            if x['latest_dialog']
            else 0,
            reverse=True
        )
        return projects
    
    def get_dialog_messages(self, composer_id: str) -> List[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞ –ø–æ ID –∫–æ–º–ø–æ–∑–µ—Ä–∞"""
        if not self.global_storage_path.exists():
            raise FileNotFoundError(
                f"–ì–ª–æ–±–∞–ª—å–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: "
                f"{self.global_storage_path}"
            )
        
        conn = sqlite3.connect(self.global_storage_path)
        cursor = conn.cursor()
        
        # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∫–æ–º–ø–æ–∑–µ—Ä–∞ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞
        cursor.execute(
            """SELECT value FROM cursorDiskKV 
            WHERE key = ? AND LENGTH(value) > 100""",
            (f'composerData:{composer_id}',)
        )
        
        composer_result = cursor.fetchone()
        ordered_bubble_ids = []
        
        if composer_result:
            try:
                composer_data = json.loads(composer_result[0])
                # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –∏–∑ fullConversationHeadersOnly
                if 'fullConversationHeadersOnly' in composer_data:
                    ordered_bubble_ids = [
                        bubble['bubbleId']
                        for bubble in 
                        composer_data['fullConversationHeadersOnly']
                    ]
            except json.JSONDecodeError:
                pass
        
        # –ï—Å–ª–∏ –Ω–µ—Ç fullConversationHeadersOnly, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥
        if not ordered_bubble_ids:
            cursor.execute(
                """SELECT rowid, key, value FROM cursorDiskKV 
                WHERE key LIKE ? AND LENGTH(value) > 100 
                ORDER BY rowid""",
                (f'bubbleId:{composer_id}:%',)
            )
            results = cursor.fetchall()
        else:
            # –ü–æ–ª—É—á–∞–µ–º –ø—É–∑—ã—Ä—å–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
            results = []
            for bubble_id in ordered_bubble_ids:
                cursor.execute(
                    """SELECT rowid, key, value FROM cursorDiskKV 
                    WHERE key = ? AND LENGTH(value) > 100""",
                    (f'bubbleId:{composer_id}:{bubble_id}',)
                )
                result = cursor.fetchone()
                if result:
                    results.append(result)
        
        conn.close()
        
        messages = []
        for rowid, key, value in results:
            try:
                bubble_data = json.loads(value)
                text = bubble_data.get('text', '').strip()
                bubble_type = bubble_data.get('type')
                tool_data = bubble_data.get('toolFormerData')
                thinking_data = bubble_data.get('thinking')
                
                message = {
                    'text': text,
                    'type': bubble_type,
                    'bubble_id': bubble_data.get('bubbleId', ''),
                    'key': key,
                    'rowid': rowid,
                    'tool_data': tool_data,
                    'attached_files': self.extract_attached_files(bubble_data),
                    'is_thought': False,  # Default to False
                    'thinking_duration': 0,  # Default to 0
                    'thinking_content': '',  # Default to empty
                    'token_count': bubble_data.get('tokenCount', {}),
                    'usage_uuid': bubble_data.get('usageUuid'),
                    'server_bubble_id': bubble_data.get('serverBubbleId'),
                    'is_agentic': bubble_data.get('isAgentic', False),
                    'capabilities_ran': bubble_data.get('capabilitiesRan', {}),
                    'unified_mode': bubble_data.get('unifiedMode'),
                    'use_web': bubble_data.get('useWeb', False),
                    'is_refunded': bubble_data.get('isRefunded', False)
                }
                
                # Check for AI thinking bubbles - improved logic
                if bubble_type == 2 and not text:
                    # Check multiple possible fields for thinking indication
                    is_thought_bubble = (
                        bubble_data.get('isThought') or
                        bubble_data.get('thinking') or
                        bubble_data.get('thinkingDurationMs') or
                        thinking_data
                    )
                    if is_thought_bubble:
                        message['is_thought'] = True
                        message['thinking_duration'] = (
                            bubble_data.get('thinkingDurationMs', 0)
                        )
                        
                        # Extract thinking content from various possible fields
                        thinking_content = ''
                        if thinking_data:
                            if isinstance(thinking_data, dict):
                                # Try different fields that might contain 
                                # thinking content
                                thinking_content = (
                                    thinking_data.get('content') or
                                    thinking_data.get('text') or
                                    thinking_data.get('thinking') or
                                    thinking_data.get('signature') or
                                    ''
                                )
                                # If signature contains encoded content, 
                                # try to decode it
                                if (thinking_content and 
                                        thinking_content.startswith('AVSoXO')):
                                    # This appears to be base64 encoded 
                                    # thinking content
                                    try:
                                        # Try to decode the signature 
                                        # (it might be base64)
                                        decoded = base64.b64decode(
                                            thinking_content)
                                        # Check if it's readable text
                                        decoded_text = decoded.decode(
                                            'utf-8', errors='ignore')
                                        if decoded_text.isprintable():
                                            thinking_content = decoded_text
                                    except Exception:
                                        # If decoding fails, show a placeholder
                                        thinking_content = (
                                            '[Thinking content available '
                                            'but encoded]')
                                elif not thinking_content:
                                    # Fallback to string representation if 
                                    # no specific field found
                                    thinking_content = (
                                        str(thinking_data) 
                                        if thinking_data else '')
                            elif isinstance(thinking_data, str):
                                thinking_content = thinking_data
                        
                        # Also check for thinking content in the main bubble data
                        if not thinking_content:
                            thinking_content = (
                                bubble_data.get('thinkingContent') or
                                bubble_data.get('thinking_content') or
                                bubble_data.get('thoughtContent') or
                                ''
                            )
                        
                        message['thinking_content'] = thinking_content
                
                # Add messages with text, tool data, attached files, or thinking data
                if (text or tool_data or message['attached_files'] or
                        message['is_thought']):
                    messages.append(message)
                    
            except json.JSONDecodeError:
                continue
        
        return messages
    
    def extract_attached_files(self, bubble_data: Dict) -> List[Dict]:
        """Extract attached files from bubble data"""
        attached_files = []
        
        # 1. –ê–∫—Ç–∏–≤–Ω—ã–π —Ñ–∞–π–ª (–æ—Ç–∫—Ä—ã—Ç—ã–π –≤ —Ä–µ–¥–∞–∫—Ç–æ—Ä–µ)
        current_file = bubble_data.get('currentFileLocationData')
        if current_file and isinstance(current_file, dict):
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø–æ–ª—è –¥–ª—è –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É
            file_path = (
                current_file.get('relativeWorkspacePath') or
                current_file.get('filePath') or
                current_file.get('path', '')
            )
            line_number = current_file.get('lineNumber', 0)
            if file_path:
                attached_files.append({
                    'type': 'active',
                    'path': file_path,
                    'line': line_number,
                    'preview': (
                        current_file.get('text') or
                        current_file.get('filePreview', '')
                    )
                })
        
        # 2. –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ–∞–π–ª—ã –∏–∑ projectLayouts
        project_layouts = bubble_data.get('projectLayouts')
        if project_layouts:
            if isinstance(project_layouts, list):
                # –ï—Å–ª–∏ —ç—Ç–æ —Å–ø–∏—Å–æ–∫ JSON-—Å—Ç—Ä–æ–∫
                for layout_str in project_layouts:
                    try:
                        layout_data = (
                            json.loads(layout_str)
                            if isinstance(layout_str, str)
                            else layout_str
                        )
                        relevant_files = self.extract_files_from_layout(
                            layout_data
                        )
                        for file_path in relevant_files:
                            attached_files.append({
                                'type': 'project',
                                'path': file_path
                            })
                    except (json.JSONDecodeError, TypeError):
                        continue
            else:
                # –ï—Å–ª–∏ —ç—Ç–æ –æ–±—ä–µ–∫—Ç
                relevant_files = self.extract_files_from_layout(project_layouts)
                for file_path in relevant_files:
                    attached_files.append({
                        'type': 'project',
                        'path': file_path
                    })
        
        # 3. –ü—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –∏–∑ codebaseContextChunks (–æ—Å–Ω–æ–≤–Ω–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫)
        codebase_chunks = bubble_data.get('codebaseContextChunks', [])
        if codebase_chunks:
            chunk_files = set()  # –ò—Å–ø–æ–ª—å–∑—É–µ–º set –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –¥—É–±–ª–µ–π
            for chunk_str in codebase_chunks:
                try:
                    if isinstance(chunk_str, str):
                        chunk = json.loads(chunk_str)
                        file_path = chunk.get('relativeWorkspacePath', '')
                        if file_path and file_path not in chunk_files:
                            chunk_files.add(file_path)
                            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —á–∞–Ω–∫–µ
                            range_info = chunk.get('range', {})
                            start_pos = range_info.get('startPosition', {})
                            end_pos = range_info.get('endPosition', {})
                            
                            attached_files.append({
                                'type': 'context',
                                'path': file_path,
                                'start_line': start_pos.get('line', 0),
                                'end_line': end_pos.get('line', 0),
                                'content_preview': (
                                    chunk.get('contents', '')[:100] + '...' 
                                    if chunk.get('contents')
                                    else ''
                                )
                            })
                except (json.JSONDecodeError, TypeError):
                    continue
        
        # 4. –í—ã–±—Ä–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (–µ—Å–ª–∏ –µ—Å—Ç—å –æ—Ç–¥–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ)
        selected_files = bubble_data.get('attachedFileCodeChunksUris', [])
        if selected_files:
            for file_uri in selected_files:
                # –ï—Å–ª–∏ —ç—Ç–æ dict —Å path, –∏–∑–≤–ª–µ–∫–∞–µ–º –ø—É—Ç—å
                if isinstance(file_uri, dict):
                    path = file_uri.get('path', str(file_uri))
                else:
                    path = str(file_uri)
                
                attached_files.append({
                    'type': 'selected',
                    'path': path
                })
        
        # 5. –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ–∞–π–ª—ã –∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –ø–æ–ª—è
        relevant_files = bubble_data.get('relevantFiles', [])
        for file_path in relevant_files:
            if isinstance(file_path, str):
                attached_files.append({
                    'type': 'relevant',
                    'path': file_path
                })
        
        # 6. –§–∞–π–ª—ã –∏–∑ context.fileSelections
        context = bubble_data.get('context', {})
        if context:
            file_selections = context.get('fileSelections', [])
            for file_sel in file_selections:
                if isinstance(file_sel, dict) and file_sel.get('path'):
                    attached_files.append({
                        'type': 'context_selected',
                        'path': file_sel.get('path'),
                        'selection': file_sel.get('selection')
                    })
        
        return attached_files
    
    def extract_files_from_layout(self, layout_data: Dict, 
                                  current_path: str = "") -> List[str]:
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏–∑–≤–ª–µ—á—å –≤—Å–µ –ø—É—Ç–∏ —Ñ–∞–π–ª–æ–≤ –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞"""
        files = []
        
        content = layout_data.get('content', {})
        if not content:
            return files
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã –≤ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        for file_info in content.get('files', []):
            if isinstance(file_info, dict) and file_info.get('name'):
                file_path = (
                    os.path.join(current_path, file_info['name'])
                    if current_path
                    else file_info['name']
                )
                files.append(file_path)
        
        # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        for dir_info in content.get('directories', []):
            if isinstance(dir_info, dict) and dir_info.get('name'):
                dir_path = (
                    os.path.join(current_path, dir_info['name'])
                    if current_path
                    else dir_info['name']
                )
                files.extend(self.extract_files_from_layout(dir_info, dir_path))
        
        return files
    
    def format_attached_files(self, attached_files: List[Dict], 
                              max_output_lines: int) -> str:
        """Format attached files for display"""
        if not attached_files:
            return ""
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –ø–æ —Ç–∏–ø–∞–º
        files_by_type = {}
        for file_info in attached_files:
            file_type = file_info.get('type', 'unknown')
            if file_type not in files_by_type:
                files_by_type[file_type] = []
            files_by_type[file_type].append(file_info)
        
        result = []
        
        # –ê–∫—Ç–∏–≤–Ω—ã–π —Ñ–∞–π–ª
        if 'active' in files_by_type:
            result.append("üìç **–ê–∫—Ç–∏–≤–Ω—ã–π —Ñ–∞–π–ª:**")
            for file_info in files_by_type['active']:
                line_info = (f" (—Å—Ç—Ä–æ–∫–∞ {file_info['line']})"
                             if file_info.get('line') else "")
                result.append(f"   `{file_info['path']}`{line_info}")
                if file_info.get('preview'):
                    # Apply truncation for active file preview
                    preview_lines = file_info['preview'].splitlines()
                    if len(preview_lines) > max_output_lines:
                        preview = (
                            "\n".join(preview_lines[:max_output_lines]) +
                            f"... ({len(preview_lines) - max_output_lines} more lines)"
                        )
                    else:
                        preview = file_info['preview']
                    result.append(f"   üí¨ {preview}")
        
        # –í—ã–±—Ä–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (—è–≤–Ω–æ –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º)
        if 'selected' in files_by_type:
            result.append("‚úÖ **–í—ã–±—Ä–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:**")
            for file_info in files_by_type['selected']:
                result.append(f"   `{file_info['path']}`")
        
        # –§–∞–π–ª—ã –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∫–æ–¥–æ–≤–æ–π –±–∞–∑—ã
        if 'context' in files_by_type:
            result.append("üìé **–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ —Ñ–∞–π–ª—ã:**")
            for file_info in files_by_type['context']:
                path = file_info['path']
                start_line = file_info.get('start_line', 0)
                end_line = file_info.get('end_line', 0)
                
                if start_line and end_line:
                    line_info = f" (—Å—Ç—Ä–æ–∫–∏ {start_line}-{end_line})"
                else:
                    line_info = ""
                
                result.append(f"   `{path}`{line_info}")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–≤—å—é —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –µ—Å–ª–∏ –µ—Å—Ç—å
                if file_info.get('content_preview'):
                    # Apply truncation for context file preview
                    preview_lines = file_info['content_preview'].splitlines()
                    if len(preview_lines) > max_output_lines:
                        preview = (
                            "\n".join(preview_lines[:max_output_lines]) +
                            f"... ({len(preview_lines) - max_output_lines} more lines)"
                        )
                    else:
                        preview = file_info['content_preview']
                    if preview:
                        result.append(f"   üí¨ {preview}")
        
        # –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ–∞–π–ª—ã
        if 'relevant' in files_by_type:
            result.append("üîó **–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ–∞–π–ª—ã:**")
            for file_info in files_by_type['relevant']:
                result.append(f"   `{file_info['path']}`")
        
        # –§–∞–π–ª—ã –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞
        if 'project' in files_by_type:
            project_files = files_by_type['project']
            result.append(
                f"üìÅ **–§–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞** ({len(project_files)} —Ñ–∞–π–ª–æ–≤):"
            )
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 10 —Ñ–∞–π–ª–æ–≤, —á—Ç–æ–±—ã –Ω–µ –∑–∞–≥—Ä–æ–º–æ–∂–¥–∞—Ç—å –≤—ã–≤–æ–¥
            for file_info in project_files[:10]:
                result.append(f"   `{file_info['path']}`")
            if len(project_files) > 10:
                result.append(f"   ... –∏ –µ—â–µ {len(project_files) - 10} —Ñ–∞–π–ª–æ–≤")
        
        # –í—ã–±—Ä–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if 'context_selected' in files_by_type:
            result.append("üéØ **–í—ã–±—Ä–∞–Ω–Ω—ã–µ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ:**")
            for file_info in files_by_type['context_selected']:
                result.append(f"   `{file_info['path']}`")
                if file_info.get('selection'):
                    result.append(f"   üìÑ –í—ã–¥–µ–ª–µ–Ω–∏–µ: {file_info['selection']}")
        
        return "\n".join(result)
    
    def format_tool_call(self, tool_data: Dict, max_output_lines: int = 1) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –≤—ã–∑–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"""
        if not tool_data or (
            tool_data.get('tool') is None and not tool_data.get('name')
        ):
            return ""
        
        tool_type = tool_data.get('tool')
        tool_name = tool_data.get('name', 'unknown')
        status = tool_data.get('status', 'unknown')
        user_decision = tool_data.get('userDecision', 'unknown')
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–∫–æ–Ω–∫—É –¥–ª—è —Ç–∏–ø–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
        tool_icon = "üîß Unknown Tool"
        if isinstance(tool_type, int) and tool_type in self.tool_types:
            tool_icon = self.tool_types[tool_type]
        elif isinstance(tool_type, int):
            tool_icon = f"üîß Tool {tool_type}"
        
        output = []
        output.append(f"üõ†Ô∏è –ò–ù–°–¢–†–£–ú–ï–ù–¢: {tool_icon}")
        output.append(f"   –ù–∞–∑–≤–∞–Ω–∏–µ: {tool_name}")
        output.append(f"   –°—Ç–∞—Ç—É—Å: {status}")
        
        if user_decision != 'unknown':
            decision_icon = "‚úÖ" if user_decision == "accepted" else "‚ùå"
            output.append(f"   –†–µ—à–µ–Ω–∏–µ: {decision_icon} {user_decision}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –µ—Å–ª–∏ –µ—Å—Ç—å
        raw_args = tool_data.get('rawArgs')
        if raw_args:
            try:
                args = json.loads(raw_args)
                output.append("   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
                for key, value in args.items():
                    if isinstance(value, str) and key == 'explanation':
                        pass  # Do not truncate explanation
                    elif (
                        tool_name in ['edit_file', 'search_replace'] and
                        key == 'code_edit'
                    ):
                        # Apply truncation for code_edit in edit_file
                        value_lines = value.splitlines()
                        if len(value_lines) > max_output_lines:
                            value = (
                                "\n".join(value_lines[:max_output_lines]) +
                                f"... ({len(value_lines) - max_output_lines} more lines)"
                            )
                        output.append(f"     {key}: {value}")
                        continue  # Skip general truncation for code_edit
                    elif isinstance(value, str) and len(value) > 70:  # general params
                        value = value[:70] + "..."
                    output.append(f"     {key}: {value}")
            except json.JSONDecodeError:
                pass
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –µ—Å–ª–∏ –µ—Å—Ç—å
        result = tool_data.get('result')
        if result:
            try:
                result_data = json.loads(result)
                output.append("   –†–µ–∑—É–ª—å—Ç–∞—Ç:")
                
                # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤
                if tool_name == 'read_file':
                    for key, value in result_data.items():
                        if key == 'contents':
                            # Apply truncation only to 'contents'
                            value_lines = str(value).splitlines()
                            if len(value_lines) > max_output_lines:
                                value_str = (
                                    "\n".join(value_lines[:max_output_lines]) +
                                    f"... ({len(value_lines) - max_output_lines} more lines)"
                                )
                            else:
                                value_str = str(value)
                            output.append(f"     {key}: {value_str}")
                        else:
                            # Display other fields without truncation
                            output.append(f"     {key}: {value}")
                
                # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Ç–µ—Ä–º–∏–Ω–∞–ª—å–Ω—ã—Ö –∫–æ–º–∞–Ω–¥
                elif tool_name == 'run_terminal_cmd':
                    cmd_output = result_data.get('output', '')
                    exit_code = result_data.get('exitCodeV2', 'unknown')
                    output.append(f"     –ö–æ–¥ –≤—ã—Ö–æ–¥–∞: {exit_code}")
                    if cmd_output:
                        # Apply truncation for command output
                        lines = cmd_output.splitlines()
                        if len(lines) > max_output_lines:
                            cmd_output = (
                                "\n".join(lines[:max_output_lines]) +
                                f"... ({len(lines) - max_output_lines} more lines)"
                            )
                        output.append(f"     –í—ã–≤–æ–¥: {cmd_output}")
                
                # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤
                elif tool_name in ['edit_file', 'search_replace']:
                    if 'diff' in result_data:
                        diff_data = result_data['diff']
                        if 'chunks' in diff_data:
                            output.append("     –ò–∑–º–µ–Ω–µ–Ω–∏—è:")
                            total_lines_added = sum(
                                chunk.get('linesAdded', 0)
                                for chunk in diff_data['chunks']
                            )
                            total_lines_removed = sum(
                                chunk.get('linesRemoved', 0)
                                for chunk in diff_data['chunks']
                            )
                            
                            if max_output_lines == 1:
                                output.append(
                                    f"       +{total_lines_added} -{total_lines_removed} "
                                    "—Å—Ç—Ä–æ–∫ (–¥–µ—Ç–∞–ª–∏ —Å–∫—Ä—ã—Ç—ã)"
                                )
                            else:
                                # Show detailed diff chunks up to max_output_lines
                                lines_shown = 0
                                for chunk in diff_data['chunks']:
                                    if lines_shown >= max_output_lines: 
                                        break
                                    diff_string = chunk.get('diffString', '')
                                    chunk_lines = diff_string.splitlines()
                                    lines_to_show = min(
                                        len(chunk_lines), max_output_lines - lines_shown
                                    )
                                    
                                    for line in chunk_lines[:lines_to_show]:
                                        output.append(f"       {line}")
                                    lines_shown += lines_to_show
                                    
                                    if len(chunk_lines) > lines_to_show:  # more lines
                                        output.append(
                                            f"       ... ({len(chunk_lines) - lines_to_show} "
                                            "more lines in chunk)"
                                        )
                                
                                if (
                                    total_lines_added + total_lines_removed > lines_shown
                                ):  # Indicate total more lines
                                    output.append(
                                        f"       ... (Total changes: +{total_lines_added} "
                                        f"-{total_lines_removed} —Å—Ç—Ä–æ–∫)"
                                    )
                
                # –î–ª—è –¥—Ä—É–≥–∏—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫—Ä–∞—Ç–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                else:
                    # Apply truncation for other results
                    if isinstance(result_data, dict):
                        items = list(result_data.items())
                        if len(items) > max_output_lines:
                            output.append(
                                f"     (–ü–æ–∫–∞–∑–∞–Ω–æ {max_output_lines} –∏–∑ {len(items)} –ø–æ–ª–µ–π)"
                            )
                            items = items[:max_output_lines]
                        for key, value in items:
                            value_str = str(value)
                            if len(value_str) > 70:  # Reduce character limit
                                value_str = value_str[:70] + "..."
                            output.append(f"     {key}: {value_str}")
                    else:
                        result_str = str(result_data)
                        lines = result_str.splitlines()
                        if len(lines) > max_output_lines:
                            result_str = (
                                "\n".join(lines[:max_output_lines]) +
                                f"... ({len(lines) - max_output_lines} more lines)"
                            )
                        output.append(f"     {result_str}")
                        
            except json.JSONDecodeError:
                pass
        
        return "\n".join(output)
    
    def format_token_info(self, message: Dict) -> str:
        """Format token usage and metadata information for a message"""
        token_count = message.get('token_count', {})
        usage_uuid = message.get('usage_uuid')
        server_bubble_id = message.get('server_bubble_id')
        is_agentic = message.get('is_agentic', False)
        capabilities_ran = message.get('capabilities_ran', {})
        unified_mode = message.get('unified_mode')
        use_web = message.get('use_web', False)
        is_refunded = message.get('is_refunded', False)
        
        if not any([token_count, usage_uuid, server_bubble_id, is_agentic, 
                    capabilities_ran, unified_mode, use_web, is_refunded]):
            return ""
        
        output = []
        
        # Token information and model inference
        if token_count:
            input_tokens = token_count.get('inputTokens', 0)
            output_tokens = token_count.get('outputTokens', 0)
            total_tokens = input_tokens + output_tokens
            
            if total_tokens > 0:
                output.append(
                    f"ü™ô –¢–û–ö–ï–ù–´: {total_tokens} "
                    f"(–≤—Ö–æ–¥: {input_tokens}, –≤—ã—Ö–æ–¥: {output_tokens})"
                )
                
                # Try to infer model from token patterns or context
                # model_hint = self.infer_model_from_context(message, total_tokens)
                # if model_hint:
                #     output.append(f"ü§ñ –ú–û–î–ï–õ–¨: {model_hint}")
                # else:
                #     output.append("ü§ñ –ú–û–î–ï–õ–¨: –ù–µ —É–∫–∞–∑–∞–Ω–∞ –≤ –ë–î")
        
        # Usage UUID (for tracking)
        # if usage_uuid:
        #     output.append(f"üÜî Usage ID: {usage_uuid}")
        
        # Server bubble ID (for debugging)
        # if server_bubble_id:
        #     output.append(f"üîó Server ID: {server_bubble_id}")
        
        # Agentic mode indicator
        if is_agentic:
            output.append("ü§ñ –†–ï–ñ–ò–ú: –ê–≥–µ–Ω—Ç—Å–∫–∏–π")
        
        # Web usage indicator
        if use_web:
            output.append("üåê –ò–°–ü–û–õ–¨–ó–£–ï–¢: –í–µ–±-–ø–æ–∏—Å–∫")
        
        # Unified mode indicator
        if unified_mode is not None:
            output.append(f"üîß –†–ï–ñ–ò–ú: Unified {unified_mode}")
        
        # Refund status
        if is_refunded:
            output.append("üí∏ –°–¢–ê–¢–£–°: –í–æ–∑–≤—Ä–∞—â–µ–Ω")
        
        # Capabilities that ran (if any significant ones)
        if capabilities_ran:
            significant_caps = []
            for cap_name, cap_list in capabilities_ran.items():
                if cap_list:  # Non-empty list
                    significant_caps.append(f"{cap_name}({len(cap_list)})")
            
            if significant_caps:
                output.append(
                    f"‚öôÔ∏è –í–û–ó–ú–û–ñ–ù–û–°–¢–ò: {', '.join(significant_caps)}"
                )
        
        return "\n".join(output)
    
    def infer_model_from_context(self, message: Dict, total_tokens: int) -> str:
        """Try to infer the model used based on available context"""
        # Check if this is an agentic message (might indicate specific models)
        if message.get('is_agentic', False):
            return "–í–µ—Ä–æ—è—Ç–Ω–æ Claude (–∞–≥–µ–Ω—Ç—Å–∫–∏–π —Ä–µ–∂–∏–º)"
        
        # Check capabilities for hints about model type
        capabilities_ran = message.get('capabilities_ran', {})
        if capabilities_ran:
            # If there are many capabilities, it might be a more advanced model
            active_caps = [cap for cap, data in capabilities_ran.items() 
                          if data]
            if len(active_caps) > 5:
                return "–í–µ—Ä–æ—è—Ç–Ω–æ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –º–æ–¥–µ–ª—å"
        
        # Check token patterns (rough heuristics)
        if total_tokens > 10000:
            return "–ë–æ–ª—å—à–∞—è –º–æ–¥–µ–ª—å (–º–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤)"
        elif total_tokens > 1000:
            return "–°—Ä–µ–¥–Ω—è—è –º–æ–¥–µ–ª—å"
        
        # Check message content for model hints
        text = message.get('text', '')
        if text:
            text_lower = text.lower()
            if any(hint in text_lower for hint in 
                   ['claude', 'sonnet', 'haiku']):
                return "Claude (—É–ø–æ–º—è–Ω—É—Ç –≤ —Ç–µ–∫—Å—Ç–µ)"
            elif any(hint in text_lower for hint in 
                     ['gpt', 'openai']):
                return "GPT (—É–ø–æ–º—è–Ω—É—Ç –≤ —Ç–µ–∫—Å—Ç–µ)"
        
        return ""
    
    def format_dialog(self, messages: List[Dict], dialog_name: str, 
                      project_name: str, max_output_lines: int) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∏–∞–ª–æ–≥ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        output = []
        output.append("=" * 60)
        output.append(f"–ü–†–û–ï–ö–¢: {project_name}")
        output.append(f"–î–ò–ê–õ–û–ì: {dialog_name}")
        output.append("=" * 60)
        output.append("")
        
        # Token counters for summary
        total_input_tokens = 0
        total_output_tokens = 0
        messages_with_tokens = 0
        
        for msg in messages:
            msg_type = msg['type']
            text = msg['text']
            tool_data = msg.get('tool_data')
            attached_files = msg.get('attached_files', [])
            is_thought = msg.get('is_thought', False)
            thinking_duration = msg.get('thinking_duration', 0)
            
            # Count tokens
            token_count = msg.get('token_count', {})
            if token_count:
                input_tokens = token_count.get('inputTokens', 0)
                output_tokens = token_count.get('outputTokens', 0)
                total_input_tokens += input_tokens
                total_output_tokens += output_tokens
                if input_tokens > 0 or output_tokens > 0:
                    messages_with_tokens += 1
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            if msg_type == 1 and text:
                output.append("üë§ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–¨:")
                output.append(text)
                
                # Token info for user messages
                token_info = self.format_token_info(msg)
                if token_info:
                    output.append("")
                    output.append(token_info)
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
                if attached_files:
                    files_output = self.format_attached_files(
                        attached_files, max_output_lines
                    )
                    if files_output:
                        output.append("")
                        output.append(files_output)
                
                output.append("-" * 40)
                output.append("")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç—ã –ò–ò
            elif msg_type == 2 and text:
                output.append("ü§ñ –ò–ò:")
                output.append(text)
                
                # Token info for AI messages
                token_info = self.format_token_info(msg)
                if token_info:
                    output.append("")
                    output.append(token_info)
                
                output.append("-" * 40)
                output.append("")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º—ã—Å–ª–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å –ò–ò
            elif is_thought:
                duration_seconds = thinking_duration / 1000.0  # Convert ms to seconds
                thinking_content = msg.get('thinking_content', '')

                # Determine if the thinking content is meaningful (i.e., not just encoded or raw JSON)
                is_meaningful_content = not (thinking_content.startswith('AVSoXO') or thinking_content.startswith('{'))

                if is_meaningful_content and thinking_content:
                    output.append(f"üí≠ –ò–ò: –ú—ã—Å–ª–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å ({duration_seconds:.1f}—Å)")
                    
                    # Apply line limiting to meaningful thinking content
                    thinking_lines = thinking_content.split('\n')
                    if max_output_lines > 0 and len(thinking_lines) > max_output_lines:
                        limited_lines = thinking_lines[:max_output_lines]
                        output.extend(limited_lines)
                        remaining_lines = len(thinking_lines) - max_output_lines
                        output.append(f"... ({remaining_lines} —Å—Ç—Ä–æ–∫ —Å–∫—Ä—ã—Ç–æ)")
                    else:
                        output.extend(thinking_lines)
                elif not is_meaningful_content and thinking_content:
                    # If it's encoded/structured but not meaningful, just show the duration line
                    output.append(f"üí≠ –ò–ò: –ú—ã—Å–ª–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å ({duration_seconds:.1f}—Å)")
                else:  # No thinking_content at all
                    output.append(f"üí≠ –ò–ò: –ú—ã—Å–ª–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å ({duration_seconds:.1f}—Å)")
                
                # Token info for thinking bubbles
                token_info = self.format_token_info(msg)
                if token_info:
                    output.append("")
                    output.append(token_info)
                
                output.append("-" * 40)
                output.append("")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—ã–∑–æ–≤—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
            elif tool_data:
                tool_output = self.format_tool_call(tool_data, max_output_lines)
                if tool_output:
                    output.append(tool_output)
                    
                    # Token info for tool calls
                    token_info = self.format_token_info(msg)
                    if token_info:
                        output.append("")
                        output.append(token_info)
                    
                    output.append("-" * 40)
                    output.append("")
            
            # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Ç–∏–ø—ã
            elif text:
                output.append(f"‚ùì –ù–ï–ò–ó–í–ï–°–¢–ù–û (—Ç–∏–ø {msg_type}):")
                output.append(text)
                
                # Token info for unknown types
                token_info = self.format_token_info(msg)
                if token_info:
                    output.append("")
                    output.append(token_info)
                
                output.append("-" * 40)
                output.append("")
        
        # Add token summary at the end
        total_tokens = total_input_tokens + total_output_tokens
        if total_tokens > 0:
            output.append("=" * 60)
            output.append("üìä –°–í–û–î–ö–ê –ü–û –¢–û–ö–ï–ù–ê–ú")
            output.append("=" * 60)
            output.append(f"–í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {total_tokens}")
            output.append(f"  ‚Ä¢ –í—Ö–æ–¥—è—â–∏–µ —Ç–æ–∫–µ–Ω—ã: {total_input_tokens}")
            output.append(f"  ‚Ä¢ –ò—Å—Ö–æ–¥—è—â–∏–µ —Ç–æ–∫–µ–Ω—ã: {total_output_tokens}")
            output.append(f"–°–æ–æ–±—â–µ–Ω–∏–π —Å —Ç–æ–∫–µ–Ω–∞–º–∏: {messages_with_tokens}")
            output.append("")
        
        return "\n".join(output)
    
    def list_projects(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤"""
        projects = self.get_projects()
        
        print("–î–û–°–¢–£–ü–ù–´–ï –ü–†–û–ï–ö–¢–´:")
        print("=" * 50)
        
        for i, project in enumerate(projects, 1):
            latest = project['latest_dialog']
            if latest:
                last_updated = datetime.fromtimestamp(
                    latest.get('lastUpdatedAt', 0) / 1000
                )
                dialog_count = len(project['composers'])
                print(f"{i:2d}. {project['project_name']}")
                print(f"    –ü—É—Ç—å: {project['folder_path']}")
                print(f"    –î–∏–∞–ª–æ–≥–æ–≤: {dialog_count}")
                print(
                    f"    –ü–æ—Å–ª–µ–¥–Ω–∏–π –¥–∏–∞–ª–æ–≥: {latest.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}"
                )
                print(
                    f"    –û–±–Ω–æ–≤–ª–µ–Ω: {last_updated.strftime('%Y-%m-%d %H:%M:%S')}"
                )
                print()
    
    def list_dialogs(self, project_name: str):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥–∏–∞–ª–æ–≥–æ–≤ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞"""
        projects = self.get_projects()
        
        # –ù–∞–π—Ç–∏ –ø—Ä–æ–µ–∫—Ç
        project = None
        for p in projects:
            if project_name.lower() in p['project_name'].lower():
                project = p
                break
        
        if not project:
            print(f"–ü—Ä–æ–µ–∫—Ç '{project_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return
        
        print(f"–î–ò–ê–õ–û–ì–ò –í –ü–†–û–ï–ö–¢–ï: {project['project_name']}")
        print("=" * 50)
        
        composers = sorted(
            project['composers'],
            key=lambda x: x.get('lastUpdatedAt', 0),
            reverse=True
        )
        
        for i, composer in enumerate(composers, 1):
            last_updated = datetime.fromtimestamp(
                composer.get('lastUpdatedAt', 0) / 1000
            )
            created = datetime.fromtimestamp(
                composer.get('createdAt', 0) / 1000
            )
            
            dialog_name_to_display = composer.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
            print(f"{i:2d}. {dialog_name_to_display}")
            print(f"    ID: {composer['composerId']}")
            print(f"    –°–æ–∑–¥–∞–Ω: {created.strftime('%Y-%m-%d %H:%M:%S')}")
            print(
                f"    –û–±–Ω–æ–≤–ª–µ–Ω: {last_updated.strftime('%Y-%m-%d %H:%M:%S')}"
            )
            print()
    
    def show_dialog(self, project_name: Optional[str] = None, 
                    dialog_name: Optional[str] = None, 
                    max_output_lines: int = 1):
        """–ü–æ–∫–∞–∑–∞—Ç—å –¥–∏–∞–ª–æ–≥"""
        projects = self.get_projects()
        
        if not projects:
            print("–ü—Ä–æ–µ–∫—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return
        
        # –í—ã–±—Ä–∞—Ç—å –ø—Ä–æ–µ–∫—Ç
        if project_name:
            project = None
            for p in projects:
                if project_name.lower() in p['project_name'].lower():
                    project = p
                    break
            if not project:
                print(f"–ü—Ä–æ–µ–∫—Ç '{project_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return
        else:
            # –°–∞–º—ã–π —Å–≤–µ–∂–∏–π –ø—Ä–æ–µ–∫—Ç
            project = projects[0]
        
        # –í—ã–±—Ä–∞—Ç—å –¥–∏–∞–ª–æ–≥
        if dialog_name:
            dialog = None
            for composer in project['composers']:
                composer_name = composer.get('name', '')
                if dialog_name.lower() in composer_name.lower():
                    dialog = composer
                    break
            if not dialog:
                print(
                    f"–î–∏–∞–ª–æ–≥ '{dialog_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø—Ä–æ–µ–∫—Ç–µ "
                    f"'{project['project_name']}'"
                )
                return
        else:
            # –°–∞–º—ã–π —Å–≤–µ–∂–∏–π –¥–∏–∞–ª–æ–≥
            if not project['composers']:
                print(f"–í –ø—Ä–æ–µ–∫—Ç–µ '{project['project_name']}' –Ω–µ—Ç –¥–∏–∞–ª–æ–≥–æ–≤")
                return
            dialog = max(
                project['composers'], key=lambda x: x.get('lastUpdatedAt', 0)
            )
        
        # –ü–æ–ª—É—á–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞
        try:
            messages = self.get_dialog_messages(dialog['composerId'])
            if not messages:
                dialog_name = dialog.get(
                    'name', f"–î–∏–∞–ª–æ–≥ {dialog['composerId'][:8]}"
                )
                print(f"–°–æ–æ–±—â–µ–Ω–∏—è –≤ –¥–∏–∞–ª–æ–≥–µ '{dialog_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                return
            
            # –û—Ç–æ–±—Ä–∞–∑–∏—Ç—å –¥–∏–∞–ª–æ–≥
            dialog_name = dialog.get(
                'name', f"–î–∏–∞–ª–æ–≥ {dialog['composerId'][:8]}"
            )
            formatted_dialog = self.format_dialog(
                messages, dialog_name, project['project_name'], max_output_lines
            )
            print(formatted_dialog)
            
        except Exception:
            print("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∏–∞–ª–æ–≥–∞")


def main():
    parser = argparse.ArgumentParser(
        description='–ü—Ä–æ—Å–º–æ—Ç—Ä –¥–∏–∞–ª–æ–≥–æ–≤ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö Cursor IDE'
    )
    parser.add_argument(
        '--project', '-p', help='–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ (—á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)'
    )
    parser.add_argument(
        '--dialog', '-d', help='–ù–∞–∑–≤–∞–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞ (—á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)'
    )
    parser.add_argument(
        '--list-projects', action='store_true', help='–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–µ–∫—Ç–æ–≤'
    )
    parser.add_argument(
        '--list-dialogs', help='–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥–∏–∞–ª–æ–≥–æ–≤ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞'
    )
    parser.add_argument(
        '--max-output-lines', '-m', type=int, default=1,
        help=(
            '–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–ª—è –≤—ã–≤–æ–¥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ '
            '–∏ –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 1)'
        )
    )
    
    args = parser.parse_args()
    
    viewer = CursorChatViewer()
    
    if args.list_projects:
        viewer.list_projects()
    elif args.list_dialogs:
        viewer.list_dialogs(args.list_dialogs)
    else:
        viewer.show_dialog(args.project, args.dialog, args.max_output_lines)


if __name__ == "__main__":
    main()
